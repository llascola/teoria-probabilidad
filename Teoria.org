#+TITLE: Teorias Probabilidad y Estadística 

* Introducción Toma Decisiones
** Introducción
La Estadistica y el Metodo Cientifico nos proveen un conjuto de  
principios y procedimientos para obtener y resumir la informacion  
para la *Toma de Decisiones*.

El metodo Cientifico comprende los siguientes pasos:
- *Formular Teorias*
- *Recolección de datos*
- *Resumen y Analisis de Datos*
- *Interpretacion de los resultados*

Estos pasos ocurren de manera cíclica. Se empieza siempre formulando
teorias, se recoleccionan datos, estos se analizan y se interpretan,
generando nuevo conocimiento y nuevas teorías sobre estos.
** Decisiones
- _Simples:_ :: Puedo cruzar la calle en esta interseccion?
- _Complejas:_ :: Supon            gamos que quiero comprar un nuevo
  auto 0KM y decido hacerlo con la General Motors. La respuesta
  a las si                         guientes preguntas puede influir sobre la decision:
  Distintos modelos producidos en el corriente año, que modelo es
  más eficiente en cuanto a Km recorridos por litro de combustible,
  en precio ?
** Lenguaje de la estadistica en la toma de Decisiones
Esta nueva terminología involucra frases, símbolos y definiciones especiales. El  
significado de una palabra es el lenguaje corriente puede ser diferente de cómo esa  
palabra está definida en el contexto de la Estadística. En esta Sección discutiremos la  
terminología estadística en el contexto del proceso de tomar decisiones. Hay muchas  
componentes en este proceso; incluye teorías, datos, una medida de “likeliness” y la  
posibilidad de errores.  
*** El ensayo de las Teorias
Competencia de teorías que sobre una población que deseamos investigar. Estas
teorías se denominan *Hipótesis Estadísticas*. Tenemos 2 tipos
+ *H_0 -> Hipótesis nula* ::
  Afirmación de que nada está sucediendo, no existe diferencia, no hay cambios
  en la población. Es la creencia convencional, el status quo.
+ *H_1 -> Hipótesis alternativa* ::
  Afirmación que el investifador espera que sea cierta. El cambio en la
  población que el investigador está buscando. Es la competencia a esa creencia.
*** Que teoría sustentar?
Si los datos son poco probables de ocurrir cuando la primer teoría es cierta
*rechazo* esta teoría y sustentamos la otra. Esto  no implica que la teoría
que sustentamos sea la cierta. La lógica detrás de la toma de decisión esta basada
en el concepto de *suceso raro*. Dado que la H_0 es en general, el status quo,
comenzamos *suponiendo que la H_0 es cierta*.

En general, la H_1 es el objetivo del investigador, puesto que la H_0 está tomada
como cierta. Cuando rechazamos H_0 en favor de H_1, se dice que los datos conducen
a un test o ensayo *Estadisticamente significativo*, es decir, los datos son poco
probables de ser observados bajo el supuesto de que H_0 es cierta.
*** Que errores podemos cometer ?
+ *Error tipo I* :: Error que se comete cuando se rechaza H_0 siendo cierta .(e_I)
+ *Error tipo II* :: Error que se comete cuando no se rechaza H_0 y es cierta la
  H_1. (e_II)

Tabla de consecuencias.

|               | H_0 es verdadera | H_1 es verdadera |
|---------------+------------------+------------------|
| Sustentar H_0 | No hay error     | e_II             |
| Sustentar H_1 | e_I              | No hay error     |

+ P(e_I): :: Probabilidad de rechazar H_0 siendo ella cierta.
+ P(e_II): :: Probabilidad de no rechazar H_0, cuando en realidad es cierta H_1

e_I es considerado muy serio, pero para lograr un valor 0 en la chance de cometer e_I,
nunca rechazaríamos la H_0. Por lo que siempre tiene que estar la chance de que se cometa
un error. Si bien queremos que P(e_I) y P(e_II) sean mínimas, cuando el número de
observaciones *está dado* no podemos controlar ambas probabilidades.

Llamamos *Nivel de significación* a un número 0 < \alpha < 1 e imponemos la condición
P(rechazar H_0 / H_0 es cierta) <= \alpha, con el objetivo de minimizar
P(no rechazar H_0/H_1 es cierta) con lo cual se maximiza la potencia del test.

Algunos valores utilizados por investigadores son de \alpha = 0.01; 0.05; 0.1

Ahora, algunas definiciones.
+ *Región Crítica/de rechazo* ::
  Conjunto de valores para los cuales rechazaríamos H_0.
+ *Región de aceptación* ::
  Conunto de valores para los cuales no rechazaríamos la H_0.
+ *Valor crítico* ::
  Aquel que marca el "punto inicial" del conjutno de valores que comprende
  la región de rechazo.
+ *Potencia del test* :: 1 - \betha.

Una *regla de decisión* es una condición matemática con la cual se acepta o no una
hipótesis dada.

Dada una regal de decisión, podemos hallar los niveles de \alpha y \betha exactamente.
También podemos ir al revés, fijar el nivel de sifnificación \alpha y a partir de él,
determinar la rega de decisión.
*** Cuán raros son los datos si H_0 es cierta?
El valor de la probabilidad asociada a un resultado /p/ es la probabilidad de obtener
el resultado observado o uno más extrmo (en dirección a la H_1), suponiendo que la H_0
es la verdadera.

Cuanto menor es el valor /p/, mayor es la evidencia provista por los
datos en contra de H_0.

El valor /p/ se compara con el nivel de sifnificación, \alpha, requerido para la toma
de decisiones.

+ Si $p \leq \alpha \implies$ se rechaza H_0 y se dice que los resultados
  /son estadísticamente significativos/.
+ Si $p \gt \alpha \implies$ no se rechaza H_0 y se dice que los resultados no son estadísticamente significativos.

Es importante distinguir entre:
+ Establecer una relga de decisión. (Antes de observar los datos)
+ Tomar una decisión. (Despues de observar los datos)

Existen 3 tipos de test de decisión (revisar)
- *Test unilateral por derecha* :: La dirección de los valores extremos se encuentran a la Derecha
- *Test unilateral por izquierd* :: La dirección de los valores extremos se encuentran a la Izquierda
- *Test bilatera* :: La dirección de los valores extremos se encuentran en ambos extremos

* La Estadística Descriptiva
La *Estadistica* es la ciencia de recolectar, analizar y 
sacar conclusiones a partir de un conjunto de datos.
En este proceso se pueden diferenciar dos partes:
- _Estadistica descriptiva:_ :: Organizar y resumir la información
  en tablas, gráficos y medidas resumen.
- _Estadística inferencial:_ :: Sacar conclusiones o tomar decisiones.

Le llamaremos *población* al conjunto de objetos acerca del cual 
se desea obtener información. Y *muestra* es un subconjunto de la
población y será lo que se estudiará para sacar conclusiones. Estas
muestras deben ser respresentativas para obtener buenas conclusiones.

Una *variable* es una característica cuyo valor, o dato, puede cambiar de un 
objeto a otro. Los conjuntos de datos se diferencian según la cantidad
de variables observables, estos pueden ser univariado, bivariado o multivariado

Las medidas resumen que se obtienen de una población se denominan
*parámetro* y los que se obtienen a partir de una muestra se llama *estadistica*.

** Tipos de variables
- _Categórica:_ :: Cada observación pertenece a un conjunto de categorías. La característica fundamental
  a describir es el número relativo de observaciones en las distintas categorías.
- _Cuatitativa:_ :: Cada observación toma valores numéricos que representan diferentes magnitudes.
  Con este tipo de variables se calculan las medidas resumen con excepción de las que no representan
  una cantidad o magnitud, ejemplo: código de área. Las característica a describir son el centro
  y la variabilidad o dispersión de los datos.
  Estas se dividen en
- _Discretas:_ :: Cada valor que toma pertenece a un conjunto discreto, como los número enteros.
- _Continua:_ :: Cada valor que toma pertenece a un conjunto continuo, como un intervalo.

** Analisis decriptivo para variables categóricas
- _Tablas de frecuencias:_ ::

  Como cada observación cae en una categoría,
  podemos usar proporciones o porcentajes (frecuencias relativas) para resumir el número de observaciones.
  La proporcion es la cantidad de observaciones de esa categoria sobre el total de las observaciones. El
  porcentaje es la proporción multiplicado por 100.

| Categoría | Frecuencia | Frecuencia Relativa | Frecuencia Relativa Porcentual|
|-----------|------------|---------------------|-------------------------------|
| Si        | 51         | 0.51                | 51%                           |
| No        | 49         | 0.49                | 49%                           |
| Total     | 100        | 1.00                | 100%                          |

- _Gráfico de torta:_ :: Consiste en un círculo con sectores, donde cada sector es una categoria.
  El tamaño del sector es proporcional a su frecuencia relativa. Se utilizan cuando hay pocas
  categorías.

- _Gráfico de barras:_ :: Consiste en barras, donde cada barra es una categoría. Las barras deben
  tener todas el mismo ancho y la altura depende de la frecuencia o frecuencia relativa de la Categoria.
  Se suelen utilizar para comparar las categorías.
- _Gráfico de Pareto:_ :: Consiste en un gráfico de barras ordenadas por su frecuencia de forma 
  descendente. Este diagrama ayuda a mostrar el principio de Pareto, "un pequeño numero de categorías 
  contiene a la mayoría de las observaciones".

** Análisis descriptivo para variables cualitativas
- _Gráfico de bastones:_ :: Consta de bastones (barras sin ancho), los cuales se utilizan para representar
  datos numéricos discritos, los cuales se originan en base a un conteo. En el eje horizontal, se colocan
  los valores que toma la variable en estudio y en el eje vertical, la frecuencia de los valores.
- _Gráfico de puntos:_ :: Cada observación se representa por un punto sobre la ubicación correspondiente a 
  su valor en una escala horizontal. Cuando un valor se presenta en mas de una ocación, se coloca por
  encima del anterior punto, esto nos da la frecuencia del valor. Se utiliza cuando el conjunto de datos 
  es pequeño ya que se muestran todas las observaciones.
- _Gráfico de tallo y hoja:_ ::  El gráfico se divide en dos partes, el tallo es la primera parte de número
  y es el primer dígito o digitos. La hoja es la última parte del npumero y son los digitos finales. Con estos 
  datos se puede obtener graficar de una manera sencilla la forma, dispersión y datos extremos o "outliers",
  estos últimos son valores muy alejados del resto. Con los gráficos de puntos y de tallo y hoja es fácil 
  reconstruir los datos originales cuando se trata de un conjunto pequeño. 
- _Histogramas:_ :: Consta de barras para mostrar las frecuencias o frecuencias relativas de las variables.
  Una variable continua asume muchos valores distintos, lo que hace necesario dividir el rango de valores en
  intervalos mas pequeños. La cantidad de intervalos se calcula como (la raiz de n) = m y la amplitud 
  como (max-min)/m.
 
También se pueden utlizar intervalos de distinta amplitud cuando hay datos que tienen
frecuencias muy extremas (bajas o altas). Para este caso, se utiliza la densidad en el eje vertical 
se cacula como frecuencia relativa sobre ancho de ese valor.
La forma del histograma nos muestra la tendencia de la variable, esta puede ser:
- _Simetrico:_ :: Si tanto, lado izquierdo como derecho mantienen una simetría respecto al centro.
- _Asimetricos:_ :: Si la cola superior del histograma se prolonga más que la cola inferior.
- _Asimetría a la derecha o positiva_ :: Si la cola derecha posee menor frecuencia que la izquierda.
- _Asimetría a la izquierda o negativa_ :: Si la cola izquierda posee menor frecuencia que la derecha.

** Medidas descriptivas para variables categóricas
- Frecuencias relativas
- Moda

** Medidas descriptivas para variables cuantitativas
- _Medidas de posición central:_ :: Se busca describir el centro o compararlo con el resto de los datos
  en relación al promedio y la mediana. El promedio tiene el problema de poder estar muy influido
  por las observaciones extremas, a diferencia de la mediana. El promedio toma en cuenta los valores y
  la mediana solamente la cantidad de observaciones.
- _Medidas de variabilidad:_ :: Son medidas que describen el grado en el cual las observaciones se
  alejan del promedio.
  - Rango = max - min.
  - Desviaciones respecto de la media: Muestra que tan alejado está un dato de la media. Se obtiene 
    restándole a la media cada observación.
  - Variancia muestral: Es la suma de las desviaciones de la media al cuadrado dividido por (n-1).
  - Desvío estándar muestral: Es la raiz cuadrada positiva de la variancia muestral.
  - Rango intercuartil: Es una medida de variabilidad resistente a los efectos de los outliers. Existen
    tres cuartiles, Q1 separa el 25% inferior del conjunto total, Q2 es la mediana que separa el 50% 
    del total y Q3 separa el 25% superior del resto. El rango intercuartil es Q3 - Q1. El gráfico que 
    muestra estos datos es el boxplot. 
 
* Probabilidad
** Experimentos aleatorios
Cuando hacemos un experimento en el cual el resultado es incierto y hay varios resultados posibles, 
nos interesa saber el grado de certeza de cada uno de los posibles resultados. Esto es lo que estudia 
la *Probabilidad*. Cabe mencionar que en un experimento entran en juego muchos factores pero nosotros 
nos centraremos en dos, las condiciones esenciales del mismo y la cantidad de repeticiones.
En cualquier experimento nos interesa saber, el procedimiento que se realizo y lo que estamos interesados
en observar. A continuacion vamos a dar una serie de definiciones que nos brinda el marco conceptual de
cualquier analisis de experimentos aleatorios.
- Espacio muestral: :: Dado un experimento 'e', definimos al espacio muestral como el conjunto de todos
  los resultados posibles. Este conjunto puede ser finito, infinito numerable o infinito no numerable.
- Suceso: :: Se le llama suceso respecto de un espacio muestral asociado al subconjunto del mismo. El 
  espacio muestral y el vacio son sucesos.
  - Si A y B son sucesos, AUB es el suceso que ocurre si A o B ocurren
  - Si A y B son sucesos, AnB es el suceso que ocurre si y solo si A y 
    B ocurren.
  - Si A es un suceso, -A es el suceso que ocurre si y solo si A no ocurre.
  - Se dice que A y B son *muetuamente excluyentes* si no pueden ocurrir juntos.
    AnB=0.
- Frecuencia relativa: :: Con el objetivo de darte un grado de certeza a los sucesos y en base a esto
  poder tener una mejor orientación sobre el resultado, se define la frecuencia relativa como la cantidad
  de apariciones de un suceso sobre el total de pruebas.
  - La frecuencia relativa está acotada por 0 y 1.
  - Si A y B son sucesos muetuamente excluyentes, f_AUB= fA + fB.
- Probabilidad de suceso: :: Se define P(A) como la frecuencia relativa de que ocurra A cuando la cantidad
  de pruebas tiende a infinito.
  - La probabilidad de un suceso está acotada por 0 y 1.
  - P(S) = 1 con S el espacio muestral.
  - P(AUB) = P(A)+P(B)
  - P(vacio) = 0
  - P(-A) = 1 - P(A)
  - Si A y B son sucesos cualesquiera, P(AUB) = P(A)+P(B)-P(AnB)
  - Si A, B y C son sucesos cualesquiera, P(AUBUC) = P(A)+P(B)+P(C)-P(AnB)-P(AnC)-P(CnB)+P(AnBnC)
  - Si A incluido en B, P(A)<= P(B)
  - Si A es un suceso que está formado por varios resultados posibles, P(A)= P(A1)+...+P(An)
  - Si los 'k' resultados son igual de probables, $P(A)=r/k, con A={A1, ..., Ar}$.
- Probabilidad condicional: :: Dados los sucesos A y B, la probabilidad condicional de B dado A, se indica 
como P(B/A) y se entiende como la probabilidad de que ocurra B dado que A ya ocurrió.
  - P(A/B) = P(AnB)/P(B).
  - Teorema de la multiplicación de probabilidades: P(A1n...nAk)= P(A1)P(A2/A1)P(A3/A1,A2)... P(Ak/A1...Ak-1)
  - P(A/B) = 0 si A y B son mutuamente excluyentes.
  - P(B/A) = 1 si A está incluido en B.
- Sucesos independientes: :: Se llaman sucesos independientes a aquellos sucesos en los cuales se sabe que si
ocurre uno, no tiene inferencia en la ocurrencia o no del otro.
  - Si A y B son sucesos independientes *si y solo si* P(AnB)= P(B)P(A)
  - Si A, B y C son sucesos independientes si y solo si 
    - P(AnB)= P(B)P(A) 
    - P(AnC)= P(B)P(C)
    - P(CnB)= P(B)P(C)
    - P(AnBnC)= P(B)P(A)P(C)
- Partición del espacio muestral: :: Se dice que los sucesos B1,...,Bk son una partición del espacio muestral
S si:
  - BinBj = vacio para todo i/=j
  - La union de todos los Bi = S 
  - P(Bi) > 0 para todo i. Esto es, cuando se realiza el experimento ocurre uno y solo uno de los sucesos Bi.
  - Sea A un suceso en S, A puede descomponerse como la unión de sucesos mutuamente excluyentes.
    - A = AnB1 U ... U AnBk
    - P(A) = P(AnB1)+ ... +P(AnBk)
    - P(A) = P(A/B1)P(B1)+...+P(A/Bk)P(Bk)
    - Teorema de Bayes: P(Bi/A)= P(A/Bi)P(Bi) / suma(P(A/Bj)P(Bj)) con j de 1 a k.
* [ ] Variables Aleatorias y Distribuciones
** Variables aleatorias discreta
Sea *X* una variable aleatoria. Si el número de valores posibles
de *X* es finito o infinito numerable, llamamos a X una variable aleatoria
discreta.

el *Rx* consta de un número de valores $ x_1, x_2, ...$, donde en el caso finito
termina con un $x_n$.

Con cada resultado posible $x_i$ asociamos
\[
    p(x_i)=P(X=x_i)
\]
Los números $p(x_i), i = 1,2,...$ deben satisfacer las condiciones
1. $p(x_i) \gq 0, \forall i$
2. \sum_{i=i}^{\inf} p(x_i) = 1

La función $p$ definida se denomina función de porbabilidad puntual de la variable
aleatoria $X$. La colección de pares $(x_i,p(x_i)), i = 1,2,...$. generalmente se
denomina
#BEGIN_CENTER
Distribución de probabilidad de X.
#END_CENTER

***
* Variables Aleatorias Continuas
Sea X: S->R, si Rx es infinito no numerable decimos que X es una variable aleatoria continua. 
Si X es una VAC existe una función /f/, llamada /funcion de densidad de probabilidad (fdp)/ de X.
  - /f(X) >=0/
  - \[ \int_{-\infty}^{\infty} f(x) \,dx\] = 1
  - Para cualquier a, b, tal que \[{-\infty}<a<b<{\infty} \] tenemos P(a<=X<=b)= \[ \int_{a}^{b} f(x) \,dx\]
- _Función de distribución acumulada:_ :: Sea X una VAC, llamamos Función de distribución acumulada a 
  - F:R->R 
    - x ->P(X<=x)= \[ \int_{-\infty}^{x} f(t) \,dt\] con /f/ la fdp asociada a X.
  - F es continua
  - F es derivable en los puntos de continuidad de /f/. F'(x) = /f(x)/
  - F es no decreciente. x1 <= x2 -> F(x1) <= F(x2)
  - \[ \lim_{{x \to -\infty}} F(x) = 0\] y \[ \lim_{{x \to \infty}} F(x) = 1\]
- _Distribución Uniforme:_ :: Supongamos que X es una variable aleatoria continua que toma todos los valores en el 
intervalo [a, b], en donde a y b son finitos. Si la fdp de X está dada por
  - /f(x)=1/b-a  a<=x<=b y 0 en otro caso/
decimos que X se distribuye uniformemente en el ese intervalo.
  - E(X) = \[ \int_{-\infty}^{\infty} xf(x) \,dx\] = (b+a)/2
  - V(X) = \[ \int_{-\infty}^{\infty} (x-E(X))^2f(x) \,dx\] = (b-a)^2/12 
  - Muestra que los resultados son igualmente probables
- _Distribución exponencial:_ :: Una variable aleatoria continua cuya fdp es 
  - \[f(x) = ae^-ax si x > 0 y sino 0\]
  Se dice que X tiene una distribución eponencial de parámetro 'a' 
  - \[ F(x)= \int_{-\infty}^{x} f(t) \,dt\] = 
    - \[\int_{-\infty}^{x} 0 \,dt\] = 0 si x < 0
    - \[\int_{-\infty}^{x} ae^-ax \,dt\] = 1 - e^-ax si x > 0
  - Propiedad de la falta de memoria: :: /[P ( X > t + a / X > a ) = P ( X > t )/] para t,a en Reales positivos
  - E(X) = \[ \int_{0}^{\infty} xae^-ax \,dx\] = 1/a
  - V(X) = \[ \int_{0}^{\infty} (x-E(X))^2ae^-ax \,dx\] = 1/(a^2)
- _Distribución normal:_ :: Una variable aleatoria X, que toma todos los valores reales -inf < x < inf, tiene una 
distribución normal o Gaussiana si su fdp es 
  - \[f(x) = \frac{1}{\sigma \sqrt{2\pi}} e^{-\frac{1}{2}\left(\frac{x - \mu}{\sigma}\right)^2}\]
Donde los parámetros \mu y \sigma deben satisfacer /-inf < \mu < inf/ y /\sigma > 0/
  - Sirve como una buena aproximación a una gran cantidad de distribuciones.
  - /f(X) >=0/
  - \[ \int_{-\infty}^{\infty} f(x) \,dx\] = 1
  - E(X) = \mu
  - V(X) = \sigma^2
  - \sqrt{V(X)} = \sigma es el desvío estándar
- _Distribución normal estandarizada_: :: ? (usar tabla :))
- _Extensión de sucesos equivalentes_: :: Sea \e un experimento y S un espacio muestral. Sea X una V.A sobre S.
Supongamos que /y=H(x)/ es una función real de x. Entonces /Y=H(X)/ es una variable aleatoria puesto que para
cada s en S se determina un valor Y, sea /y=H[X(s)]/
  - Rx es el conjunto de valores posibles para x
  - Ry es el conjunto de valores posibles para Y 
Sea C un suceso asociado a Ry. Se define el suceso B en Rx como: los x en Rx tal que H(x) esté en C. Entonces, 
B es el conjunto de valores de X tal que H(x) está en C. A los sucesos B y C se los llama *equivalentes*.
  - P(C) es la probabilidad del suceso equivalente en función de X, esto es, P[{x en Rx tal que H(x) está en C}]
- _Teorema de la fdp para Y_: :: Sea X una VAC con fdp /f(x)/, sea /y=H(x)/ una función *estrictamente* 
*monótona y derivable para todo x*. La VAC /Y=H(X)/ tiene como fdp \[/f_y(y)=f_x(x)\frac{\partial f}{\partial x}\]/ 
donde /x = H^-1(y)/
/*hay propiedades pero me parecen basura*/
* TODO Variables Aleatorias n-dimensionales
* Procesos Estocasticos: Cadena de Markov, Poisson y Bernulli
Un proceso estocástio es una sucesión de variables aleatorias \(X_t\) parametrizadas por un t \in T es el espacio 
paramétrico. Estas variables pueden o no ser dependientes unas de otras o tener distribuciones distintas.
- /T/ es e factor que pueda determinar un cambio en el comportamiento de nuestro proceso, en general es el tiempo. 
- /E/ es el conjunto de todos los posibles resultados del proceso. 
Entonces, un proceso estocástico se puede ver de dos formas 
- El conjunto de \({X_t:\omega->R, t \in T}\)
- Una sola variable aleatoria con dos argumentos /X(\omega,t)/
La interpretación es, dado un suceso \omega0, /X_t(\omega0)/ equivale al estado del proceso en el momento /t/. Esto 
es totalmente determinista, ya que el suceso ya está definido, y solo veremos como evoluciona con el paso del tiempo.
De forma análoga, para /t_0/ fijo, /X_t0(\omega)/ es la variable aleatoria que ocurre en el instante t. Esto ya no es 
determinista, porque depende del suceso aleatorio /\omega/.
En particular destacamos algunos procesos estocásticos
- /T/ discreto y /E/ discreto: :: Se modelan con Cadenas de Markov o procesos de Bernoulli 
- /T/ continuo y /E/ discreto: :: Se modelan con procesos puntuales, como procesos de Poisson

** Cadenas de Markov 
Las cadenas de Markov modelan procesos estocásticos donde 
- Espacio paramétrico /T/ infinito y numerable (discreto).
- Espacio de estados /E/ discreto 
- Propiedad markoviana: El próximo estado *solo* depende del estado actual del sistema (pérdida de memoria)
La importancia de la propiedad markoviana es que dado el presente, no solo se puede conocer la probabilidad del instante 
/n+1/ sino también cualquier /n+m/ y así reconstruir el futuro.
El diagrama de transiciones de una cadena de Markov es un grafo ponderado dirigido, donde cada vertice es un estado y 
existe una arista entre dos estados si hay una probabilidad mayor a 0 de transicionar de uno al otro.
Esta representación nos permite utilizar lo que en teoría de grafos se llama *matriz de transición* notada como /P(i,j/ 
que cumple con las siguientes propiedades.
- Es cuadrada de tamaño nxn donde n es /|E|/ 
- /P(i,j) >= 0/
- La sumatoria de cada vector fila es igual a 1
- P(X0 = i0 , X1 = i1 , . . . , Xn = in ) = P(in-1 ,in)...P(i0 ,i1)P(X0 = i0). Lo que nos dice esto es que si conocemos
todas las probabilidades de transición y la distribución inicial, entonces podemos calcular de manera exacta la 
probabilidad con que se dará cada posible evolución de X.
- P(Xm+n = j|Xm = i) = P^n(i, j). Esto es, la probabilidad de transicionar en n pasos de i a j es igual a la suma de las
probabilidades de todos los caminos de longitud n que van de i a j. Esta suma de probabilidades de caminos es lo que 
P^n(i, j) representa.
- P^n+m(i, j) = \(\sum\limits_{k=1}^{n} P^n(i, k)P^m(k, j)\) . Esta propiedad nos dice que la probabilidad de una 
transición en n + m pasos se puede separar en |E| pares de transiciones, donde en cada par la primera transición es en n
pasos desde i hasta k, y la segunda va desde k hasta j en m pasos. Esta propiedad lleva el nombre de Chapman-Kolmogorov.
- Sea π0 un vector de probabilidades, luego P (Xn = i) = πn (i) donde πn = π0 ·P^n
- _Estados recurrentes y transitorios_: :: Decimos que un estado j es recurrente si F(j, j) = 1. Caso contrario, 
si F(j, j) < 1 se dice que j es un estado transitorio. Los estados recurrentes se dividen a su vez en dos categorías, los 
positivamente recurrentes y nulo recurrentes. Un estado j es positivamente recurrente si y solo si el tiempo promedio 
entre dos visitas consecutivas a j es finito, mientras que en los estados nulo recurrentes este tiempo promedio es infinito.
Un estado transitorio tiene la propiedad de que solo se transita un número finito de veces, mientras que cuando un estado 
recurrente es visitado, entonces se lo volverá a visitar una cantidad infinita de veces. Esto es así porque un estado j es 
transitorio si F (j, j) < 1, luego 1 - F (j, j) > 0 por lo que la probabilidad de no volver a j es no nula, lo cual 
significa que a la larga dejaremos de pasar por este. 
  - Teorema: 
  . Si j es transitivo o recurrente nulo, entonces ∀i ∈ E, lim n→∞ P^n(i, j) = 0. De no ser así, a la larga terminaríamos 
  regresando a j en una cantidad finita de pasos.
  . Si j es recurrente positivo y aperiódico e i está en algún conjunto cerrado con j, entonces vale que lim n→∞ P^n(i, j) > 0.
  Más aún, para cualquier i ∈ E se tiene lim n→∞ P^n(i, j) = F(i, j)lim n→∞ P^n(j, j).
- _Absorción:_ :: Un estado j es absorbente si P (j, j) = 1. Esto implica que ∀i /= j P(j, i) = 0. En el grafo, un estado 
absorbente se caracteriza por tener un lazo en j y ningún otro arco saliente de j.
- _Accesibilidad:_ :: Decimos que j es accesible desde i si ∃n ∈ N0 : P^n(i, j)>0. Esto es, j es accesible desde i si hay 
algún camino dirigido en el grafo de transiciones desde i hasta j de cualquier longitud finita.
  - Teorema: Sean i, j ∈ E tales que i → j y además i es recurrente. Entonces j es recurrente.
La intuición de por qué esto es cierto es sencilla. Si j fuese transitivo, entonces es porque
eventualmente no se vuelve a j, y por ende no se debe poder volver a i. Pero i es recurrente,
luego se tiene un absurdo.
- _Conjuntos cerrados e irreducibles:_ :: 
  -Un conjunto C ⊆ E es cerrado si ningún estado en E \ C es accesible desde algún estado
  en j. E es siempre cerrado.
  - Un conjunto cerrado C se dice irreducible si ∀S ⊂ C, S no es cerrado. Cuando E sea irreducible, diremos que la cadena 
  es irreducible, y esta propiedad se refleja en el grafo cuando para cada par de estados i, j se tiene i → j.
  - Si C ⊆ E cerrado e irreducible y finito, entonces ∀i ∈ C, i es positivamente recurrente.
  - Sea j ∈ E un estado recurrente, luego existe C ⊆ E irreducible tal que j ∈ C.
    - Teorema: Sea C = {j ∈ E : j es recurrente}. C se puede particionar de manera única en conjuntos irreducibles. Además,
    si Ck es una componente de esta partición, entonces Ck es una cadena de Markov irreducible. A cada una de estas Cj las 
    llamaremos clases de recurrencia ya que forman una clase de equivalencia bajo la relación de alcanzabilidad.
    - Teorema: Si se tiene una cadena de Markov irreducible, entonces sus estados son todos recurrentes o todos transitivos.
    - Teorema: 
      - Sean i, j estados recurrentes que pertenecen al mismo conjunto irreducible, entonces F(i, j) = 1.
      - Sean i, j estados recurrentes que pertenecen a distintos conjuntos irreducibles, entonces F(i, j) = 0
      - Sea i un estado transitivo y C ⊂ E un conjunto irreducible. Entonces F(i, j) = F(i, k) ∀j, k ∈ C.
    - Corolario: Tenemos que si existe una única clase recurrente C e i es un estado transitivo del cual solo un numero
    finito de estados transitivos pueden ser alcanzados, luego F(i, j) = 1 ∀j ∈ C.
- _Periodo:_ :: Sea j un estado recurrente, se define δ = mcd {n ≥ 1 : P^n (j, j) > 0}. Si δ ≥ 2 entonces decimos que j 
es un estado periódico con período δ. Por otro lado, cuando δ = 1 decimos que j es un estado aperiódico.
  - Si se tiene una cadena irreducible y un estado de período δ, entonces todos los estados tienen período δ y se dice 
  que la cadena es periódica de período δ. Si un estado es aperiódico, todos los estados lo serán y se dice que la cadena 
  es aperiódica.
- _Ergodicidad:_ :: Sea X una cadena con cantidad finita de estados. Se dice que X es ergódica si y solo si X es irreducible, 
recurrente y aperiódica. Notemos que pedir que es recurrente aquí no es necesario, ya que esto se puede deducir de la 
irreduciblidad y cantidad finita de sus estados.
- _Matrices canónicas y fundamentales:_ :: Si i es recurrente y j transitivo, entonces es un hecho que P (i, j) = 0, luego 
si tomamos un orden de los estados i1 ,...,in ,j1 ,... ,jm con ik recurrente y jk transitivo, donde n es la cantidad de 
estados recurrentes y m la de transitivos, si reescribimos P en este orden, se tendrá un bloque de ceros en la región 
superior derecha. (ver resumen bati pag 10).
 -Una observación muy importante para esto es ver que, en cierto sentido, las clases de recurrencia se comportan como estados
 absorbentes. No se puede salir de los estados absorbentes al igual que de las clases de recurrencia, y entonces no podemos ir
 de una clase de recurrencia a otra.

